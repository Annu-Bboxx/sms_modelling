{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28dc3a14",
   "metadata": {},
   "source": [
    "#### Reading data from csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f74753",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_df.to_csv(r'/Users/annukajla/Desktop/Rwanda_sms_pred_demo.csv', index=False)\n",
    "final_df=pd.read_csv(r\"/Users/annukajla/Desktop/Rwanda_sms_pred_demo.csv\")\n",
    "df=final_df[:690000]  #taking a subset of dataset to run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6485516",
   "metadata": {},
   "source": [
    "Distribution of paid and not paid customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop target variable\n",
    "X = df.drop(['target'], axis=1)\n",
    "\n",
    "y =df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d58282",
   "metadata": {},
   "source": [
    "### Optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2056db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_threshold(y, y_hat, beta):\n",
    "    precision, recall, thresholds = precision_recall_curve(y, y_hat)\n",
    "    nonzero_idx = np.where((recall != 0) & (precision != 0))  \n",
    "    fscore = (beta * beta + 1) * precision[nonzero_idx] * recall[nonzero_idx] / \\\n",
    "             (beta * beta * precision[nonzero_idx] + recall[nonzero_idx])\n",
    "    optimal_idx = np.argmax(fscore)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "def probabilities_to_binary(probabilities, threshold):\n",
    "    return np.where(probabilities >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ecf9a",
   "metadata": {},
   "source": [
    "### Function for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat(y_test,y_pred):\n",
    "    matrix = confusion_matrix(y_test, y_pred,normalize='all').round(2)\n",
    "#     matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(7,5))\n",
    "    ax = plt.subplot()\n",
    "    sns.set(font_scale=1.5) # Adjust to fit\n",
    "    sns.heatmap(matrix, annot=True, ax=ax, cmap=\"Greens\", fmt=\"g\");  \n",
    "    class_names = ['not paid', 'paid']\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    tick_marks2 = tick_marks + 0.5\n",
    "    \n",
    "    # Labels, title and ticks\n",
    "    label_font = {'size':'12'}  # Adjust to fit\n",
    "    ax.set_xlabel('Predictions', fontdict=label_font);\n",
    "    ax.set_ylabel('Actual', fontdict=label_font);\n",
    "    plt.xticks(tick_marks, class_names, rotation=25)\n",
    "    plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "    # plt.yticks([0.5,1.5], ['good prospects - ', 'bad prospects - '],rotation=0)\n",
    "\n",
    "\n",
    "    # plt.xticks([0.5,1.5], ['| \\n% of customers allowed \\nby the CP', '| \\n% of customers denied \\nby the CP'])\n",
    "\n",
    "    title_font = {'size':'21'}  # Adjust to fit\n",
    "    # ax.set_title('Breakdown of current process against ground truth', fontdict=title_font);\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14)  # Adjust to fit\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Build the plot\n",
    "  \n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d3580",
   "metadata": {},
   "source": [
    "### model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ce6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_binary_clf = lgb.LGBMClassifier(\n",
    "  objective=\"binary\",\n",
    "    metric='',\n",
    "    max_depth= -1,\n",
    "    silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825c00e",
   "metadata": {},
   "source": [
    "### Selecting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_grid_space =    {\n",
    "    'n_estimators': np.arange(50,550,50),\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(100, 150,3)),\n",
    "    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base = 10, num = 500)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10)),\n",
    "    'subsample': list(np.linspace(0.5, 1, 100)),\n",
    "    'scale_pos_weight': [1, 1.3, 1.5]\n",
    "}\n",
    "\n",
    "# setup CV parameters\n",
    "n_jobs = -1\n",
    "beta = 0.5\n",
    "seed = 42\n",
    "verbose = 1\n",
    "cv = 4\n",
    "test_size=0.25\n",
    "n_combinations = 10  \n",
    "\n",
    "#stratified_kfolds to do cross validation\n",
    "stratified_kfolds = StratifiedKFold(n_splits=cv, random_state=seed, shuffle=True)\n",
    "\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=beta)    # using fbeta_score as metrics\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=lgbm_binary_clf,\n",
    "                               n_iter=n_combinations,\n",
    "                               n_jobs=n_jobs,\n",
    "                               param_distributions=hyperparameters_grid_space,\n",
    "                               random_state=seed,\n",
    "                               scoring=ftwo_scorer,\n",
    "                               cv = stratified_kfolds,\n",
    "                               verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c2c76",
   "metadata": {},
   "source": [
    "### Nested Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def nested_cv(train_features,train_target,random_cv,model):\n",
    "outer_cv_params = []\n",
    "outer_cv_scores = []\n",
    "outer_cv_ots = []\n",
    "\n",
    "for train_idx, test_idx in stratified_kfolds.split(X, y):\n",
    "    X_train_cv = X.iloc[train_idx]\n",
    "    X_test_cv = X.iloc[test_idx]\n",
    "    y_train_cv = y.iloc[train_idx]\n",
    "    y_test_cv = y.iloc[test_idx]\n",
    "    X_resampled, y_resampled = os.fit_resample(X_train_cv, y_train_cv)\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=beta)\n",
    "    # cv to tuning\n",
    "    random_cv.fit(X_resampled, y_resampled)\n",
    "    outer_cv_params.append(random_cv.best_params_)\n",
    "#     print(y_resampled.value_counts())\n",
    "    # train model with best params\n",
    "    lgbm_binary_clf.set_params(**random_cv.best_params_)\n",
    "    lgbm_binary_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # predict on testset\n",
    "    y_hat = lgbm_binary_clf.predict(X_test_cv)\n",
    "    target_test_predicted_proba = lgbm_binary_clf.predict_proba(X_test_cv)[:, 1]\n",
    "    \n",
    "    # tune threshold\n",
    "    ot = optimal_threshold(y_test_cv, target_test_predicted_proba, beta=beta)\n",
    "    outer_cv_ots.append(ot)\n",
    "    \n",
    "    # convert to probabilities and score\n",
    "    y_test_pred = probabilities_to_binary(target_test_predicted_proba, ot)\n",
    "    score = fbeta_score(y_test_cv, y_test_pred,beta=beta).round(2)\n",
    "    outer_cv_scores.append(score)\n",
    "   # F1_score = f1_score(y_test_cv,y_hat,average='weighted')\n",
    "    #outer_cv_scores.append(F1_score)\n",
    "    print(outer_cv_scores,ot)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880bf6b3",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = random_cv.best_params_\n",
    "lgbm_binary_clf.set_params(**best_params)  \n",
    "lgbm_binary_clf.fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_binary_clf.predict_proba(X)[:,1]\n",
    "print(y_pred)\n",
    "\n",
    "# tune threshold\n",
    "optimal_th = optimal_threshold(y, y_pred, beta=0.5)\n",
    "predicted_classes = probabilities_to_binary(y_pred, optimal_th)\n",
    "# score\n",
    "total_score = fbeta_score(y, predicted_classes,beta=beta)\n",
    "\n",
    "print(\"total score\",round(total_score, 2))\n",
    "pd.value_counts(predicted_classes, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075f2a35",
   "metadata": {},
   "source": [
    "### Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat(y,predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf44d8",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "k_explainer = shap.TreeExplainer(lgbm_binary_clf)\n",
    "\n",
    "shap_values = k_explainer.shap_values(X)\n",
    "shap.summary_plot(shap_values[1], X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182749dc",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58461e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([X, y], axis=1)\n",
    "result['predicted_target'] = predicted_classes.tolist()\n",
    "result['predicted_target_probabilities']=y_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[(result[\"target\"] == 1) & (result[\"predicted_target\"] == 1), \"TP/FN\"] = 'TP'\n",
    "result.loc[(result[\"target\"] == 0) & (result[\"predicted_target\"] == 0), \"TP/FN\"] = 'TN'\n",
    "result.loc[(result[\"target\"] == 0) & (result[\"predicted_target\"] == 1), \"TP/FN\"] = 'FP'\n",
    "result.loc[(result[\"target\"] == 1) & (result[\"predicted_target\"] == 0), \"TP/FN\"] = 'FN'\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306a968",
   "metadata": {},
   "source": [
    "Wrong predictions  by the model (FP/FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['TP/FN'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed2cdb",
   "metadata": {},
   "source": [
    "False Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a0566",
   "metadata": {},
   "outputs": [],
   "source": [
    "False_neg=result[result['TP/FN']=='FN']\n",
    "False_neg=False_neg.sort_values(by=['predicted_target_probabilities'], ascending=False)\n",
    "print(\"Total FN cases\",len(False_neg))\n",
    "False_neg.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7285f",
   "metadata": {},
   "source": [
    "False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "False_pos=result[result['TP/FN']=='FP']\n",
    "False_pos=False_pos.sort_values(by=['predicted_target_probabilities'], ascending=False)\n",
    "print(\"Total FP cases\",len(False_pos))\n",
    "False_pos.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error_analysis=result[[ 'daily_rate',\n",
    "       'utilisation_rate', 'balance_left', 'age', 'days_customer_in_bbox',\n",
    "        'Total_no_of_payments','TP/FN']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e283b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=7, cols=1,\n",
    "#     subplot_titles=(\"Plot 1\", \"Plot 2\", \"Plot 3\", \"Plot 4\",\"Plot 5\",\"Plot 6\",\"Plot 7\",\"Plot 8\")\n",
    ")\n",
    "counter=0\n",
    "#y_data=df_error_analysis[df_error_analysis.columns]\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)', 'rgba(44, 160, 101, 0.5)','rgba(255, 65, 54, 0.5)']\n",
    "x_data = ['TN ', 'TP',\n",
    "          'FP', 'FN',]\n",
    "for i in range(1,8):\n",
    "    if counter < 8:\n",
    "        fig.add_trace(go.Box(y=df_error_analysis[df_error_analysis.columns[counter]],\n",
    "                x=df_error_analysis['TP/FN'],quartilemethod=\"linear\"),\n",
    "                  row=counter+1, col=1)\n",
    "\n",
    "\n",
    "        fig.update_yaxes(title_text=df_error_analysis.columns[counter],row=counter+1, col=1)\n",
    "        counter+=1\n",
    "#fig.update_traces(boxpoints='all', jitter=0)\n",
    "fig.update_layout(height=1600, width=1200,showlegend=False,\n",
    "                  title_text=\"Multiple Subplots with Titles\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1300ec6",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "    Total 3 day reminder msgs sent till date:7.4M\n",
    "    Total 3 day reminder msgs sent in year 2022: 1.2M\n",
    "    1) Messages sent to invalid phone number:\n",
    "        i)total 3.8 million msgs sent to invalid phone numbers till date'\n",
    "        ii)500K msgs in 2022\n",
    "        iii)100K msgs for 3 day reminder in year 2022\n",
    "        \n",
    "    2) Messages sent to repossessed customers\n",
    "        i)73K msgs sent to repossessed customers till date\n",
    "        ii)40K msgs sent to repossessed customers for year 2022\n",
    "\n",
    "    4) Did not find any duplication of messages for rwanda\n",
    "    \n",
    "    5)dataset after cleaning =1.6 Million for year 2022:\n",
    "        paid:65%\n",
    "        not paid:35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db03c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
